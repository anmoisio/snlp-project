oisioa3@remorse ~/snlp-project/word_language_model
 % python3 main.py --cuda --data yle_norm --emmodel ../data/embeddings/Word2Vec_iltalehti-wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin --save w2v_wp-il_yle_norm.pt
using pretrained word embeddings ../data/embeddings/Word2Vec_iltalehti-wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin
encoder layer shape torch.Size([142249, 200])
OOV count 67292
| epoch   1 |   200/ 2605 batches | lr 20.00 | ms/batch 58.61 | loss  8.52 | ppl  5036.46
| epoch   1 |   400/ 2605 batches | lr 20.00 | ms/batch 57.94 | loss  7.42 | ppl  1667.98
| epoch   1 |   600/ 2605 batches | lr 20.00 | ms/batch 58.06 | loss  7.04 | ppl  1140.46
| epoch   1 |   800/ 2605 batches | lr 20.00 | ms/batch 57.92 | loss  6.81 | ppl   904.81
| epoch   1 |  1000/ 2605 batches | lr 20.00 | ms/batch 57.80 | loss  6.72 | ppl   832.06
| epoch   1 |  1200/ 2605 batches | lr 20.00 | ms/batch 57.74 | loss  6.65 | ppl   775.76
| epoch   1 |  1400/ 2605 batches | lr 20.00 | ms/batch 57.72 | loss  6.56 | ppl   707.85
| epoch   1 |  1600/ 2605 batches | lr 20.00 | ms/batch 57.78 | loss  6.45 | ppl   632.65
| epoch   1 |  1800/ 2605 batches | lr 20.00 | ms/batch 57.77 | loss  6.38 | ppl   590.36
| epoch   1 |  2000/ 2605 batches | lr 20.00 | ms/batch 57.75 | loss  6.32 | ppl   558.06
| epoch   1 |  2200/ 2605 batches | lr 20.00 | ms/batch 57.74 | loss  6.29 | ppl   536.63
| epoch   1 |  2400/ 2605 batches | lr 20.00 | ms/batch 57.82 | loss  6.33 | ppl   561.81
| epoch   1 |  2600/ 2605 batches | lr 20.00 | ms/batch 57.79 | loss  6.22 | ppl   502.29
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 161.31s | valid loss  6.39 | valid ppl   593.73
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 2605 batches | lr 20.00 | ms/batch 58.03 | loss  6.26 | ppl   522.18
| epoch   2 |   400/ 2605 batches | lr 20.00 | ms/batch 57.84 | loss  6.18 | ppl   482.62
| epoch   2 |   600/ 2605 batches | lr 20.00 | ms/batch 57.86 | loss  6.02 | ppl   410.69
| epoch   2 |   800/ 2605 batches | lr 20.00 | ms/batch 57.86 | loss  5.98 | ppl   393.90
| epoch   2 |  1000/ 2605 batches | lr 20.00 | ms/batch 57.80 | loss  6.08 | ppl   436.01
| epoch   2 |  1200/ 2605 batches | lr 20.00 | ms/batch 57.86 | loss  6.05 | ppl   422.52
| epoch   2 |  1400/ 2605 batches | lr 20.00 | ms/batch 57.82 | loss  6.03 | ppl   417.41
| epoch   2 |  1600/ 2605 batches | lr 20.00 | ms/batch 57.94 | loss  5.95 | ppl   383.06
| epoch   2 |  1800/ 2605 batches | lr 20.00 | ms/batch 57.84 | loss  5.90 | ppl   364.55
| epoch   2 |  2000/ 2605 batches | lr 20.00 | ms/batch 57.93 | loss  5.89 | ppl   361.85
| epoch   2 |  2200/ 2605 batches | lr 20.00 | ms/batch 57.87 | loss  5.88 | ppl   356.82
| epoch   2 |  2400/ 2605 batches | lr 20.00 | ms/batch 57.87 | loss  5.94 | ppl   380.81
| epoch   2 |  2600/ 2605 batches | lr 20.00 | ms/batch 57.91 | loss  5.86 | ppl   351.72
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 161.14s | valid loss  6.19 | valid ppl   487.31
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 2605 batches | lr 20.00 | ms/batch 58.10 | loss  5.93 | ppl   374.99
| epoch   3 |   400/ 2605 batches | lr 20.00 | ms/batch 58.11 | loss  5.86 | ppl   351.51
| epoch   3 |   600/ 2605 batches | lr 20.00 | ms/batch 58.08 | loss  5.71 | ppl   301.80
| epoch   3 |   800/ 2605 batches | lr 20.00 | ms/batch 58.01 | loss  5.69 | ppl   295.58
| epoch   3 |  1000/ 2605 batches | lr 20.00 | ms/batch 57.95 | loss  5.83 | ppl   339.36
| epoch   3 |  1200/ 2605 batches | lr 20.00 | ms/batch 58.02 | loss  5.79 | ppl   326.12
| epoch   3 |  1400/ 2605 batches | lr 20.00 | ms/batch 57.84 | loss  5.79 | ppl   327.46
| epoch   3 |  1600/ 2605 batches | lr 20.00 | ms/batch 58.07 | loss  5.72 | ppl   303.74
| epoch   3 |  1800/ 2605 batches | lr 20.00 | ms/batch 58.00 | loss  5.67 | ppl   289.79
| epoch   3 |  2000/ 2605 batches | lr 20.00 | ms/batch 57.97 | loss  5.67 | ppl   290.92
| epoch   3 |  2200/ 2605 batches | lr 20.00 | ms/batch 57.89 | loss  5.66 | ppl   286.34
| epoch   3 |  2400/ 2605 batches | lr 20.00 | ms/batch 58.22 | loss  5.73 | ppl   308.67
| epoch   3 |  2600/ 2605 batches | lr 20.00 | ms/batch 58.15 | loss  5.67 | ppl   289.85
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 161.88s | valid loss  6.10 | valid ppl   445.89
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 2605 batches | lr 20.00 | ms/batch 58.42 | loss  5.73 | ppl   307.80
| epoch   4 |   400/ 2605 batches | lr 20.00 | ms/batch 58.20 | loss  5.68 | ppl   292.34
| epoch   4 |   600/ 2605 batches | lr 20.00 | ms/batch 58.49 | loss  5.53 | ppl   251.96
| epoch   4 |   800/ 2605 batches | lr 20.00 | ms/batch 58.45 | loss  5.51 | ppl   248.05
| epoch   4 |  1000/ 2605 batches | lr 20.00 | ms/batch 58.22 | loss  5.67 | ppl   289.60
| epoch   4 |  1200/ 2605 batches | lr 20.00 | ms/batch 58.21 | loss  5.62 | ppl   276.50
| epoch   4 |  1400/ 2605 batches | lr 20.00 | ms/batch 58.11 | loss  5.64 | ppl   281.23
| epoch   4 |  1600/ 2605 batches | lr 20.00 | ms/batch 58.35 | loss  5.56 | ppl   260.89
| epoch   4 |  1800/ 2605 batches | lr 20.00 | ms/batch 58.40 | loss  5.52 | ppl   249.19
| epoch   4 |  2000/ 2605 batches | lr 20.00 | ms/batch 58.33 | loss  5.53 | ppl   252.83
| epoch   4 |  2200/ 2605 batches | lr 20.00 | ms/batch 58.59 | loss  5.51 | ppl   248.04
| epoch   4 |  2400/ 2605 batches | lr 20.00 | ms/batch 58.64 | loss  5.58 | ppl   265.51
| epoch   4 |  2600/ 2605 batches | lr 20.00 | ms/batch 58.48 | loss  5.53 | ppl   251.25
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 162.59s | valid loss  6.07 | valid ppl   432.99
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 2605 batches | lr 20.00 | ms/batch 58.78 | loss  5.60 | ppl   269.39
| epoch   5 |   400/ 2605 batches | lr 20.00 | ms/batch 58.55 | loss  5.54 | ppl   255.42
| epoch   5 |   600/ 2605 batches | lr 20.00 | ms/batch 58.95 | loss  5.39 | ppl   219.78
| epoch   5 |   800/ 2605 batches | lr 20.00 | ms/batch 58.85 | loss  5.38 | ppl   217.69
| epoch   5 |  1000/ 2605 batches | lr 20.00 | ms/batch 58.31 | loss  5.54 | ppl   255.46
| epoch   5 |  1200/ 2605 batches | lr 20.00 | ms/batch 58.76 | loss  5.50 | ppl   244.09
| epoch   5 |  1400/ 2605 batches | lr 20.00 | ms/batch 58.70 | loss  5.52 | ppl   249.65
| epoch   5 |  1600/ 2605 batches | lr 20.00 | ms/batch 58.84 | loss  5.44 | ppl   231.25
| epoch   5 |  1800/ 2605 batches | lr 20.00 | ms/batch 58.98 | loss  5.40 | ppl   221.93
| epoch   5 |  2000/ 2605 batches | lr 20.00 | ms/batch 58.92 | loss  5.42 | ppl   225.59
| epoch   5 |  2200/ 2605 batches | lr 20.00 | ms/batch 58.96 | loss  5.40 | ppl   221.52
| epoch   5 |  2400/ 2605 batches | lr 20.00 | ms/batch 59.09 | loss  5.47 | ppl   237.65
| epoch   5 |  2600/ 2605 batches | lr 20.00 | ms/batch 58.82 | loss  5.42 | ppl   225.55
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 163.55s | valid loss  6.05 | valid ppl   423.78
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 2605 batches | lr 20.00 | ms/batch 59.36 | loss  5.49 | ppl   241.97
| epoch   6 |   400/ 2605 batches | lr 20.00 | ms/batch 59.04 | loss  5.43 | ppl   229.09
| epoch   6 |   600/ 2605 batches | lr 20.00 | ms/batch 59.36 | loss  5.29 | ppl   198.92
| epoch   6 |   800/ 2605 batches | lr 20.00 | ms/batch 59.42 | loss  5.28 | ppl   197.08
| epoch   6 |  1000/ 2605 batches | lr 20.00 | ms/batch 58.98 | loss  5.45 | ppl   233.44
| epoch   6 |  1200/ 2605 batches | lr 20.00 | ms/batch 59.17 | loss  5.40 | ppl   220.92
| epoch   6 |  1400/ 2605 batches | lr 20.00 | ms/batch 59.09 | loss  5.42 | ppl   226.06
| epoch   6 |  1600/ 2605 batches | lr 20.00 | ms/batch 59.11 | loss  5.35 | ppl   211.25
| epoch   6 |  1800/ 2605 batches | lr 20.00 | ms/batch 59.28 | loss  5.31 | ppl   201.38
| epoch   6 |  2000/ 2605 batches | lr 20.00 | ms/batch 59.59 | loss  5.32 | ppl   204.75
| epoch   6 |  2200/ 2605 batches | lr 20.00 | ms/batch 59.42 | loss  5.31 | ppl   201.61
| epoch   6 |  2400/ 2605 batches | lr 20.00 | ms/batch 59.35 | loss  5.37 | ppl   215.22
| epoch   6 |  2600/ 2605 batches | lr 20.00 | ms/batch 59.09 | loss  5.33 | ppl   205.86
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 164.86s | valid loss  6.04 | valid ppl   420.88
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  6.00 | test ppl   403.03
=========================================================================================
moisioa3@remorse ~/snlp-project/word_language_model
 % python3 generate.py --cuda --data yle_norm --outf gener_w2v_wp-il_norm.txt --checkpoint w2v_wp-il_norm.pt                                                                                          Traceback (most recent call last):
  File "generate.py", line 48, in <module>
    with open(args.checkpoint, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'w2v_wp-il_norm.pt'
moi                                                                                                moisioa3@remorse ~/snlp-project/word_language_model
 %
moisioa3@remorse ~/snlp-project/word_language_model
 %
moisioa3@remorse ~/snlp-project/word_language_model
 % python3 generate.py --cuda --data yle_norm --outf gener_w2v_wp-il_norm.txt --checkpoint w2v_wp-il_yle_norm.pt
| Generated 0/1000 words
| Generated 100/1000 words
| Generated 200/1000 words
| Generated 300/1000 words
| Generated 400/1000 words
| Generated 500/1000 words
| Generated 600/1000 words
| Generated 700/1000 words
| Generated 800/1000 words
| Generated 900/1000 words
moisioa3@remorse ~/snlp-project/word_language_model