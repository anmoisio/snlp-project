moisioa3@ook ~/snlp-project/word_language_model
 % python3 main.py --cuda --data yle_norm --emmodel ../data/embeddings/Word2Vec_wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin --save w2v_wp_yle_norm.pt
using pretrained word embeddings ../data/embeddings/Word2Vec_wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin
encoder layer shape torch.Size([142249, 200])
OOV count 88300
| epoch   1 |   200/ 2605 batches | lr 20.00 | ms/batch 70.15 | loss  8.54 | ppl  5104.26
| epoch   1 |   400/ 2605 batches | lr 20.00 | ms/batch 70.23 | loss  7.42 | ppl  1675.58
| epoch   1 |   600/ 2605 batches | lr 20.00 | ms/batch 69.56 | loss  7.05 | ppl  1157.37
| epoch   1 |   800/ 2605 batches | lr 20.00 | ms/batch 69.72 | loss  6.83 | ppl   926.44
| epoch   1 |  1000/ 2605 batches | lr 20.00 | ms/batch 69.89 | loss  6.75 | ppl   849.85
| epoch   1 |  1200/ 2605 batches | lr 20.00 | ms/batch 69.62 | loss  6.68 | ppl   799.75
| epoch   1 |  1400/ 2605 batches | lr 20.00 | ms/batch 69.59 | loss  6.60 | ppl   737.54
| epoch   1 |  1600/ 2605 batches | lr 20.00 | ms/batch 69.68 | loss  6.48 | ppl   649.74
| epoch   1 |  1800/ 2605 batches | lr 20.00 | ms/batch 69.35 | loss  6.42 | ppl   613.29
| epoch   1 |  2000/ 2605 batches | lr 20.00 | ms/batch 69.53 | loss  6.36 | ppl   575.37
| epoch   1 |  2200/ 2605 batches | lr 20.00 | ms/batch 69.92 | loss  6.32 | ppl   553.73
| epoch   1 |  2400/ 2605 batches | lr 20.00 | ms/batch 69.36 | loss  6.37 | ppl   581.53
| epoch   1 |  2600/ 2605 batches | lr 20.00 | ms/batch 68.72 | loss  6.26 | ppl   524.92
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 193.38s | valid loss  6.40 | valid ppl   602.97
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 2605 batches | lr 20.00 | ms/batch 68.96 | loss  6.29 | ppl   540.37
| epoch   2 |   400/ 2605 batches | lr 20.00 | ms/batch 69.52 | loss  6.23 | ppl   505.72
| epoch   2 |   600/ 2605 batches | lr 20.00 | ms/batch 69.75 | loss  6.07 | ppl   431.42
| epoch   2 |   800/ 2605 batches | lr 20.00 | ms/batch 69.62 | loss  6.02 | ppl   410.88
| epoch   2 |  1000/ 2605 batches | lr 20.00 | ms/batch 69.45 | loss  6.12 | ppl   453.06
| epoch   2 |  1200/ 2605 batches | lr 20.00 | ms/batch 69.53 | loss  6.09 | ppl   443.41
| epoch   2 |  1400/ 2605 batches | lr 20.00 | ms/batch 69.72 | loss  6.08 | ppl   437.75
| epoch   2 |  1600/ 2605 batches | lr 20.00 | ms/batch 69.42 | loss  6.00 | ppl   401.62
| epoch   2 |  1800/ 2605 batches | lr 20.00 | ms/batch 69.53 | loss  5.95 | ppl   382.82
| epoch   2 |  2000/ 2605 batches | lr 20.00 | ms/batch 69.52 | loss  5.95 | ppl   381.96
| epoch   2 |  2200/ 2605 batches | lr 20.00 | ms/batch 69.68 | loss  5.92 | ppl   372.43
| epoch   2 |  2400/ 2605 batches | lr 20.00 | ms/batch 70.04 | loss  5.99 | ppl   400.63
| epoch   2 |  2600/ 2605 batches | lr 20.00 | ms/batch 69.70 | loss  5.91 | ppl   370.46
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 193.19s | valid loss  6.22 | valid ppl   501.78
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 2605 batches | lr 20.00 | ms/batch 69.53 | loss  5.97 | ppl   392.68
| epoch   3 |   400/ 2605 batches | lr 20.00 | ms/batch 69.58 | loss  5.92 | ppl   373.05
| epoch   3 |   600/ 2605 batches | lr 20.00 | ms/batch 69.49 | loss  5.76 | ppl   318.30
| epoch   3 |   800/ 2605 batches | lr 20.00 | ms/batch 70.26 | loss  5.74 | ppl   309.90
| epoch   3 |  1000/ 2605 batches | lr 20.00 | ms/batch 69.03 | loss  5.87 | ppl   355.92
| epoch   3 |  1200/ 2605 batches | lr 20.00 | ms/batch 68.97 | loss  5.85 | ppl   347.62
| epoch   3 |  1400/ 2605 batches | lr 20.00 | ms/batch 69.32 | loss  5.85 | ppl   346.92
| epoch   3 |  1600/ 2605 batches | lr 20.00 | ms/batch 69.10 | loss  5.76 | ppl   318.71
| epoch   3 |  1800/ 2605 batches | lr 20.00 | ms/batch 69.72 | loss  5.72 | ppl   304.95
| epoch   3 |  2000/ 2605 batches | lr 20.00 | ms/batch 69.66 | loss  5.73 | ppl   308.97
| epoch   3 |  2200/ 2605 batches | lr 20.00 | ms/batch 69.27 | loss  5.71 | ppl   302.56
| epoch   3 |  2400/ 2605 batches | lr 20.00 | ms/batch 69.92 | loss  5.78 | ppl   324.59
| epoch   3 |  2600/ 2605 batches | lr 20.00 | ms/batch 69.24 | loss  5.72 | ppl   304.79
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 192.86s | valid loss  6.16 | valid ppl   472.51
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 2605 batches | lr 20.00 | ms/batch 69.90 | loss  5.79 | ppl   326.72
| epoch   4 |   400/ 2605 batches | lr 20.00 | ms/batch 70.03 | loss  5.74 | ppl   309.94
| epoch   4 |   600/ 2605 batches | lr 20.00 | ms/batch 69.97 | loss  5.59 | ppl   266.90
| epoch   4 |   800/ 2605 batches | lr 20.00 | ms/batch 69.76 | loss  5.57 | ppl   261.30
| epoch   4 |  1000/ 2605 batches | lr 20.00 | ms/batch 69.97 | loss  5.72 | ppl   306.41
| epoch   4 |  1200/ 2605 batches | lr 20.00 | ms/batch 69.71 | loss  5.68 | ppl   293.86
| epoch   4 |  1400/ 2605 batches | lr 20.00 | ms/batch 69.46 | loss  5.70 | ppl   297.46
| epoch   4 |  1600/ 2605 batches | lr 20.00 | ms/batch 71.17 | loss  5.61 | ppl   274.26
| epoch   4 |  1800/ 2605 batches | lr 20.00 | ms/batch 70.03 | loss  5.57 | ppl   262.10
| epoch   4 |  2000/ 2605 batches | lr 20.00 | ms/batch 70.29 | loss  5.59 | ppl   267.76
| epoch   4 |  2200/ 2605 batches | lr 20.00 | ms/batch 69.58 | loss  5.57 | ppl   261.15
| epoch   4 |  2400/ 2605 batches | lr 20.00 | ms/batch 69.72 | loss  5.64 | ppl   281.50
| epoch   4 |  2600/ 2605 batches | lr 20.00 | ms/batch 69.70 | loss  5.58 | ppl   266.20
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 194.16s | valid loss  6.10 | valid ppl   445.28
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 2605 batches | lr 20.00 | ms/batch 69.64 | loss  5.65 | ppl   284.84
| epoch   5 |   400/ 2605 batches | lr 20.00 | ms/batch 69.97 | loss  5.60 | ppl   271.46
| epoch   5 |   600/ 2605 batches | lr 20.00 | ms/batch 70.47 | loss  5.46 | ppl   234.98
| epoch   5 |   800/ 2605 batches | lr 20.00 | ms/batch 70.52 | loss  5.45 | ppl   231.66
| epoch   5 |  1000/ 2605 batches | lr 20.00 | ms/batch 70.14 | loss  5.61 | ppl   272.74
| epoch   5 |  1200/ 2605 batches | lr 20.00 | ms/batch 69.64 | loss  5.56 | ppl   260.60
| epoch   5 |  1400/ 2605 batches | lr 20.00 | ms/batch 70.20 | loss  5.58 | ppl   265.35
| epoch   5 |  1600/ 2605 batches | lr 20.00 | ms/batch 70.07 | loss  5.50 | ppl   244.09
| epoch   5 |  1800/ 2605 batches | lr 20.00 | ms/batch 70.71 | loss  5.46 | ppl   234.47
| epoch   5 |  2000/ 2605 batches | lr 20.00 | ms/batch 70.27 | loss  5.48 | ppl   238.95
| epoch   5 |  2200/ 2605 batches | lr 20.00 | ms/batch 70.94 | loss  5.46 | ppl   234.78
| epoch   5 |  2400/ 2605 batches | lr 20.00 | ms/batch 71.49 | loss  5.53 | ppl   250.94
| epoch   5 |  2600/ 2605 batches | lr 20.00 | ms/batch 69.77 | loss  5.48 | ppl   239.80
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 195.15s | valid loss  6.09 | valid ppl   442.46
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 2605 batches | lr 20.00 | ms/batch 70.47 | loss  5.55 | ppl   257.00
| epoch   6 |   400/ 2605 batches | lr 20.00 | ms/batch 70.33 | loss  5.50 | ppl   243.55
| epoch   6 |   600/ 2605 batches | lr 20.00 | ms/batch 70.76 | loss  5.36 | ppl   211.93
| epoch   6 |   800/ 2605 batches | lr 20.00 | ms/batch 70.50 | loss  5.34 | ppl   207.63
| epoch   6 |  1000/ 2605 batches | lr 20.00 | ms/batch 70.30 | loss  5.51 | ppl   248.30
| epoch   6 |  1200/ 2605 batches | lr 20.00 | ms/batch 70.74 | loss  5.47 | ppl   236.83
| epoch   6 |  1400/ 2605 batches | lr 20.00 | ms/batch 70.99 | loss  5.49 | ppl   242.03
| epoch   6 |  1600/ 2605 batches | lr 20.00 | ms/batch 70.88 | loss  5.41 | ppl   223.21
| epoch   6 |  1800/ 2605 batches | lr 20.00 | ms/batch 71.11 | loss  5.37 | ppl   213.97
| epoch   6 |  2000/ 2605 batches | lr 20.00 | ms/batch 71.35 | loss  5.39 | ppl   218.90
| epoch   6 |  2200/ 2605 batches | lr 20.00 | ms/batch 71.09 | loss  5.36 | ppl   213.75
| epoch   6 |  2400/ 2605 batches | lr 20.00 | ms/batch 70.57 | loss  5.44 | ppl   229.43
| epoch   6 |  2600/ 2605 batches | lr 20.00 | ms/batch 70.70 | loss  5.39 | ppl   219.71
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 196.34s | valid loss  6.10 | valid ppl   446.55
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  6.06 | test ppl   428.52
=========================================================================================
moisioa3@ook ~/snlp-project/word_language_model
 % python3 generate.py --cuda --data yle_norm --outf gener_w2v_wp_norm.txt --checkpoint w2v_wp_norm.pt
Traceback (most recent call last):
  File "generate.py", line 48, in <module>
    with open(args.checkpoint, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'w2v_wp_norm.pt'
moisioa3@ook ~/snlp-project/word_language_model
 % python3 generate.py --cuda --data yle_norm --outf gener_w2v_wp_norm.txt --checkpoint w2v_wp_yle_norm.pt
| Generated 0/1000 words
| Generated 100/1000 words
| Generated 200/1000 words
| Generated 300/1000 words
| Generated 400/1000 words
| Generated 500/1000 words
| Generated 600/1000 words
| Generated 700/1000 words
| Generated 800/1000 words
| Generated 900/1000 words