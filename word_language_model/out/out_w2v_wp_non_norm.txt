moisioa3@smith ~/snlp-project/word_language_model
 % python3 main.py --cuda --data yle --emmodel ../data/embeddings/Word2Vec_wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin --save w2v_wp_yle.pt
using pretrained word embeddings ../data/embeddings/Word2Vec_wikipedia_new_size=200,alpha=0.025,window=10,min_count=2,sg=1,negative=5,iter=10.bin
encoder layer shape torch.Size([379997, 200])
OOV count 347311
| epoch   1 |   200/ 2108 batches | lr 20.00 | ms/batch 168.17 | loss 11.24 | ppl 75954.33
| epoch   1 |   400/ 2108 batches | lr 20.00 | ms/batch 167.61 | loss 10.53 | ppl 37594.30
| epoch   1 |   600/ 2108 batches | lr 20.00 | ms/batch 167.62 | loss 10.19 | ppl 26661.23
| epoch   1 |   800/ 2108 batches | lr 20.00 | ms/batch 167.85 | loss 10.04 | ppl 22854.37
| epoch   1 |  1000/ 2108 batches | lr 20.00 | ms/batch 172.19 | loss  9.97 | ppl 21323.12
| epoch   1 |  1200/ 2108 batches | lr 20.00 | ms/batch 186.03 | loss  9.77 | ppl 17515.22
| epoch   1 |  1400/ 2108 batches | lr 20.00 | ms/batch 167.24 | loss  9.71 | ppl 16504.01
| epoch   1 |  1600/ 2108 batches | lr 20.00 | ms/batch 167.81 | loss  9.61 | ppl 14862.21
| epoch   1 |  1800/ 2108 batches | lr 20.00 | ms/batch 167.77 | loss  9.54 | ppl 13895.99
| epoch   1 |  2000/ 2108 batches | lr 20.00 | ms/batch 167.71 | loss  9.53 | ppl 13763.75
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 380.93s | valid loss  9.66 | valid ppl 15712.67
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 2108 batches | lr 20.00 | ms/batch 168.77 | loss  9.42 | ppl 12358.61
| epoch   2 |   400/ 2108 batches | lr 20.00 | ms/batch 167.74 | loss  9.32 | ppl 11196.94
| epoch   2 |   600/ 2108 batches | lr 20.00 | ms/batch 167.96 | loss  9.08 | ppl  8801.53
| epoch   2 |   800/ 2108 batches | lr 20.00 | ms/batch 167.45 | loss  9.19 | ppl  9837.90
| epoch   2 |  1000/ 2108 batches | lr 20.00 | ms/batch 167.76 | loss  9.22 | ppl 10059.44
| epoch   2 |  1200/ 2108 batches | lr 20.00 | ms/batch 167.71 | loss  9.12 | ppl  9092.72
| epoch   2 |  1400/ 2108 batches | lr 20.00 | ms/batch 167.67 | loss  9.03 | ppl  8389.59
| epoch   2 |  1600/ 2108 batches | lr 20.00 | ms/batch 167.75 | loss  8.98 | ppl  7948.43
| epoch   2 |  1800/ 2108 batches | lr 20.00 | ms/batch 167.62 | loss  8.94 | ppl  7659.59
| epoch   2 |  2000/ 2108 batches | lr 20.00 | ms/batch 167.86 | loss  8.98 | ppl  7927.36
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 376.57s | valid loss  9.26 | valid ppl 10544.56
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 2108 batches | lr 20.00 | ms/batch 168.41 | loss  8.92 | ppl  7474.45
| epoch   3 |   400/ 2108 batches | lr 20.00 | ms/batch 167.81 | loss  8.86 | ppl  7019.88
| epoch   3 |   600/ 2108 batches | lr 20.00 | ms/batch 168.73 | loss  8.60 | ppl  5454.18
| epoch   3 |   800/ 2108 batches | lr 20.00 | ms/batch 167.65 | loss  8.78 | ppl  6482.71
| epoch   3 |  1000/ 2108 batches | lr 20.00 | ms/batch 167.64 | loss  8.80 | ppl  6626.23
| epoch   3 |  1200/ 2108 batches | lr 20.00 | ms/batch 168.12 | loss  8.71 | ppl  6044.42
| epoch   3 |  1400/ 2108 batches | lr 20.00 | ms/batch 168.25 | loss  8.63 | ppl  5608.83
| epoch   3 |  1600/ 2108 batches | lr 20.00 | ms/batch 170.05 | loss  8.58 | ppl  5342.96
| epoch   3 |  1800/ 2108 batches | lr 20.00 | ms/batch 170.03 | loss  8.55 | ppl  5154.07
| epoch   3 |  2000/ 2108 batches | lr 20.00 | ms/batch 168.81 | loss  8.61 | ppl  5472.87
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 378.15s | valid loss  9.13 | valid ppl  9201.01
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 2108 batches | lr 20.00 | ms/batch 169.78 | loss  8.56 | ppl  5223.40
| epoch   4 |   400/ 2108 batches | lr 20.00 | ms/batch 169.83 | loss  8.50 | ppl  4935.94
| epoch   4 |   600/ 2108 batches | lr 20.00 | ms/batch 169.79 | loss  8.25 | ppl  3821.83
| epoch   4 |   800/ 2108 batches | lr 20.00 | ms/batch 170.02 | loss  8.45 | ppl  4674.55
| epoch   4 |  1000/ 2108 batches | lr 20.00 | ms/batch 169.79 | loss  8.48 | ppl  4821.86
| epoch   4 |  1200/ 2108 batches | lr 20.00 | ms/batch 170.71 | loss  8.40 | ppl  4428.52
| epoch   4 |  1400/ 2108 batches | lr 20.00 | ms/batch 170.33 | loss  8.31 | ppl  4062.52
| epoch   4 |  1600/ 2108 batches | lr 20.00 | ms/batch 170.20 | loss  8.26 | ppl  3853.40
| epoch   4 |  1800/ 2108 batches | lr 20.00 | ms/batch 170.65 | loss  8.24 | ppl  3775.13
| epoch   4 |  2000/ 2108 batches | lr 20.00 | ms/batch 170.37 | loss  8.30 | ppl  4027.63
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 381.55s | valid loss  9.05 | valid ppl  8503.50
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 2108 batches | lr 20.00 | ms/batch 171.37 | loss  8.26 | ppl  3859.47
| epoch   5 |   400/ 2108 batches | lr 20.00 | ms/batch 170.43 | loss  8.20 | ppl  3658.33
| epoch   5 |   600/ 2108 batches | lr 20.00 | ms/batch 170.21 | loss  7.96 | ppl  2849.98
| epoch   5 |   800/ 2108 batches | lr 20.00 | ms/batch 171.21 | loss  8.17 | ppl  3531.33
| epoch   5 |  1000/ 2108 batches | lr 20.00 | ms/batch 171.06 | loss  8.19 | ppl  3609.98
| epoch   5 |  1200/ 2108 batches | lr 20.00 | ms/batch 170.79 | loss  8.12 | ppl  3357.58
| epoch   5 |  1400/ 2108 batches | lr 20.00 | ms/batch 170.20 | loss  8.04 | ppl  3088.13
| epoch   5 |  1600/ 2108 batches | lr 20.00 | ms/batch 171.09 | loss  7.98 | ppl  2920.47
| epoch   5 |  1800/ 2108 batches | lr 20.00 | ms/batch 170.48 | loss  7.97 | ppl  2892.14
| epoch   5 |  2000/ 2108 batches | lr 20.00 | ms/batch 170.30 | loss  8.03 | ppl  3069.06
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 382.66s | valid loss  9.02 | valid ppl  8235.24
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 2108 batches | lr 20.00 | ms/batch 171.32 | loss  8.00 | ppl  2976.75
| epoch   6 |   400/ 2108 batches | lr 20.00 | ms/batch 170.46 | loss  7.95 | ppl  2837.73
| epoch   6 |   600/ 2108 batches | lr 20.00 | ms/batch 170.51 | loss  7.70 | ppl  2212.49
| epoch   6 |   800/ 2108 batches | lr 20.00 | ms/batch 171.03 | loss  7.93 | ppl  2785.76
| epoch   6 |  1000/ 2108 batches | lr 20.00 | ms/batch 170.89 | loss  7.95 | ppl  2823.25


| epoch   6 |  1200/ 2108 batches | lr 20.00 | ms/batch 170.29 | loss  7.87 | ppl  2624.65
| epoch   6 |  1400/ 2108 batches | lr 20.00 | ms/batch 170.60 | loss  7.78 | ppl  2401.34
| epoch   6 |  1600/ 2108 batches | lr 20.00 | ms/batch 170.55 | loss  7.74 | ppl  2300.41
| epoch   6 |  1800/ 2108 batches | lr 20.00 | ms/batch 170.79 | loss  7.74 | ppl  2299.39
| epoch   6 |  2000/ 2108 batches | lr 20.00 | ms/batch 170.43 | loss  7.80 | ppl  2432.79
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 382.60s | valid loss  9.03 | valid ppl  8340.84
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  9.01 | test ppl  8158.63
=========================================================================================
moisioa3@smith ~/snlp-project/word_language_model
 %
moisioa3@smith ~/snlp-project/word_language_model
 %
moipython3 generate.py --cuda --data yle_norm --outf gener_w2v_wp_yle_non_norm.txt --checkpoint w2v_wp_yle.pt
| Generated 0/1000 words
Traceback (most recent call last):r=10.bin --save w2v_wp_yle.pt
  File "generate.py", line 76, in <module>
    word = corpus.dictionary.idx2word[word_idx]
IndexError: list index out of range
moisioa3@smith ~/snlp-project/word_language_model
 % python3 generate.py --cuda --data yle --outf gener_w2v_wp_yle_non_norm.txt --checkpoint w2v_wp_yle.pt
| Generated 0/1000 words
| Generated 100/1000 words
| Generated 200/1000 words
| Generated 300/1000 words
| Generated 400/1000 words
| Generated 500/1000 words
| Generated 600/1000 words
| Generated 700/1000 words
| Generated 800/1000 words
| Generated 900/1000 words
moisioa3@smith ~/snlp-project/word_language_model